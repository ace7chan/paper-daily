# Exploring Self-attention for Image Recognition

### 摘要

Recent work has shown that self-attention can serve as a basic building block for image recognition models. We explore variations of self-attention and assess their effectiveness for image recognition. We consider two forms of self-attention. One is pairwise self-attention, which generalizes standard dot-product attention and is fundamentally a set operator. The other is patchwise self-attention, which is strictly more powerful than convolution. Our pairwise self-attention networks match or outperform their convolutional counterparts, and the patchwise models substantially outperform the convolutional baselines. We also conduct experiments that probe the robustness of learned representations and conclude that self-attention networks may have significant benefits in terms of robustness and generalization.

> PS: 作者既然用了may这个词！！！

### 创新点

- 提出了两种self-attention的变种（其实可以看作local-self-attention），并将convolution模块采用self-attention模块替换掉；在保证相近参数量和计算量的前提下，作者提出的结构能够显著提升ImageNet上面的分类性能
- 作者发现基于self-attention结构的网络鲁棒性和泛化性更好

### 实现细节

在具体介绍下述操作时，先给出这篇论文在下述self-attention上实现采用的结构（放前面更容易对下述公式各部分含义的理解）：

![](png/san_1.png)

#### 1. Pairwise Self-attention

![](png/san_2.png)

- 一句话概括：输出位置的信息来自于当前位置和周边位置的加权和，而权重和当前位置和周边位置的相似度呈正相关
- $\beta,\psi, \varphi$都是FC，$\gamma$是FC+ReLU+FC
- 其中的$R(i)$往往就是位置$i$附件的$k\times k$方框内的信息
- 但是上述方式缺少位置信息，即$k\times k$内部随便打乱对结果都不影响，这或许不是我们希望的，因此需要加入position encoding：此处对$i,j$位置进行编码（采用FC），然后将两者的差值再$\gamma$之前与$\delta$进行融合

#### 2. Patchwise Self-attention

![](png/san_3.png)

- 和pairwise不同的是，不是非得利用和$x_i$的相似性，而是将邻近区域信息进行大融合作为系数

> 可以认为pairwise是每次$i,j$先建立关系，再和$x_j$相乘；而patchwise则是每次$i$和一些列邻近点建立关系，然后将其作为依据去建立和$j$的情况

#### 3. 网络结构

![](png/san_4.png)

- 除了第一个Block采用的$R(i)$大小是$3\times 3$，其余的都采用$7\times 7$

### 实验结果

① SAN vs CNN

![](png/san_4.png)

② 采用不同relation function $\delta$的性能

![](png/san_6.png)

③ 鲁棒性实验

![](png/san_7.png)

- 其中括号里面的代表相较原始图片性能下降的情况



